# web服务器端口号
server.port=8080

# openAi配置项
#langchain4j.open-ai.chat-model.base-url=http://langchain4j.dev/demo/openai/v1
#langchain4j.open-ai.chat-model.api-key=demo
#langchain4j.open-ai.chat-model.model-name=gpt-4o-mini

# DeepSeek,实质上也使用了OpenAi的接口,只不过底层接入的大模型的配置参数发生了改变
#langchain4j.open-ai.chat-model.base-url=https://api.deepseek.com/v1
# 读取系统环境变量,如有修改,需重启IDEA
#langchain4j.open-ai.chat-model.api-key=${DEEPSEEK_API_KEY}
#langchain4j.open-ai.chat-model.model-name=deepseek-chat

# ollama
langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=deepseek-r1:1.5b
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true

# 这两个配置专用于LangChain4j+OpenAI的组合,如果使用其他模型或框架,需设置对应的日志控制机制
# 应用程序发送给大模型的请求日志响应日志
langchain4j.open-ai.chat-model.log-requests=true
langchain4j.open-ai.chat-model.log-responses=true
# 设置系统日志设置为debug级别
logging.level.root=debug